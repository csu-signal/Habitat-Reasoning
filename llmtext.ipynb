{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w0Ear4cVNV4-",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HF_HOME\"] = \"pathtocache\"\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from PIL import Image, ImageOps\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "from lavis.models import load_model_and_preprocess\n",
        "from lavis.processors import load_processor\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9L1h8zZ8JRh",
        "tags": []
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_csv(file_path):\n",
        "    return pd.read_csv(file_path, encoding='latin-1')\n",
        "\n",
        "\n",
        "\n",
        "def list_files(directory):\n",
        "    return os.listdir(directory)\n",
        "\n",
        "def list_folders_with_numbers(directory):\n",
        "    folders_with_numbers = []\n",
        "    folders = [folder for folder in os.listdir(directory) if os.path.isdir(os.path.join(directory, folder))]\n",
        "    for folder in folders:\n",
        "        if any(char.isdigit() for char in folder):\n",
        "            folders_with_numbers.append(folder)\n",
        "    folders_with_numbers.sort(key=lambda x: int(''.join(filter(str.isdigit, x))))\n",
        "    return folders_with_numbers\n",
        "\n",
        "\n",
        "def select_rows(csv_data, files_directory):\n",
        "    selected_rows = []\n",
        "    files = list_folders_with_numbers(files_directory)\n",
        "\n",
        "    for filename in files:\n",
        "        try:\n",
        "            file_index = int(filename.split('-')[1])\n",
        "            selected_rows.append(csv_data.iloc[file_index-2])\n",
        "\n",
        "\n",
        "        except (ValueError, IndexError):\n",
        "            pass\n",
        "\n",
        "    return selected_rows\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    csv_file_path = '<pathftofile>'\n",
        "    files_directory = '<pathtoimagefiles>'\n",
        "\n",
        "    csv_data = read_csv(csv_file_path)\n",
        "    selected_rows = select_rows(csv_data, files_directory)\n",
        "\n",
        "\n",
        "    custom_index = list(range(0,len(selected_rows)))\n",
        "    df_syn = pd.DataFrame(selected_rows, columns=['Questions', 'answers'],index=custom_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZHfptzSmx1N",
        "tags": []
      },
      "outputs": [],
      "source": [
        "directory_name = f\"<pathtodirectory>\"\n",
        "\n",
        "\n",
        "if not os.path.exists(directory_name):\n",
        "\n",
        "    os.makedirs(directory_name)\n",
        "    print(\"Directory created:\", directory_name)\n",
        "else:\n",
        "    print(\"Directory already exists:\", directory_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7jtqn1smx1O"
      },
      "source": [
        "# Text-only LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQB-eHLhmx1O"
      },
      "source": [
        "## Flan-T5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QK6UjrG_mx1O",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_name = \"google/flan-t5-small\"\n",
        "\n",
        "\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhxSBTDYmx1P",
        "tags": []
      },
      "outputs": [],
      "source": [
        "eval_prompt_1 = df_syn['Questions'].tolist()\n",
        "\n",
        "\n",
        "test_lst = []\n",
        "for i in eval_prompt_1:\n",
        "    item = \"Answer with the option's letter from the given choices directly and don't provide extra choices or explanations.\" + '\\n' + i + '\\n' + \"Answer is:\"\n",
        "\n",
        "    inputs = tokenizer(item, return_tensors=\"pt\").to('cuda')\n",
        "    generate_ids = model.generate(**inputs, max_new_tokens=100)\n",
        "    test = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    test_lst.append(test)\n",
        "\n",
        "df_llama_2_7b = pd.DataFrame({'col1': test_lst})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAIvbyV9mx1P"
      },
      "source": [
        "## flan-alpaca-gpt4-xl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tGp6w8fmx1P",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_name = \"declare-lab/flan-alpaca-gpt4-xl\"\n",
        "\n",
        "\n",
        "model = pipeline(model=model_name, device_map= 'auto')\n",
        "\n",
        "\n",
        "\n",
        "eval_prompt_1 = df_syn['Questions'].tolist()\n",
        "\n",
        "\n",
        "test_lst = []\n",
        "for i in eval_prompt_1:\n",
        "    item = \"Answer with the option's letter from the given choices directly and don't provide extra choices or explanations.\" + '\\n' + i + '\\n' + \"Answer is:\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        test = model(item, max_length=128, do_sample=True)\n",
        "        test_lst.append(test)\n",
        "\n",
        "df_llama_2_7b = pd.DataFrame({'col1': test_lst})\n",
        "df_llama_2_7b.loc[0, 'col1']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9ZhBQCUmx1Q"
      },
      "source": [
        "## LLaMA-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3iCf9ZPmx1Q",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_name = \"meta-llama/Llama-2-70b-chat-hf\"\n",
        "\n",
        "\n",
        "access_token = \"<access_token>\"\n",
        "\n",
        "cache_dir = \"pathtocache\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "load_in_4bit=True,\n",
        "bnb_4bit_use_double_quant=True,\n",
        "bnb_4bit_quant_type=\"nf4\",\n",
        "bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(model_name, device_map=\"auto\",\n",
        "                                         quantization_config=bnb_config,\n",
        "                                         use_auth_token=access_token,\n",
        "                                         torch_dtype=torch.float16,\n",
        "                                         cache_dir = cache_dir,\n",
        "                                         attn_implementation=\"flash_attention_2\"\n",
        "                                        )\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
        "                                          use_fast=True,\n",
        "                                          use_auth_token=access_token,\n",
        "                                          cache_dir = cache_dir\n",
        "                                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ryIoSbamx1R",
        "tags": []
      },
      "outputs": [],
      "source": [
        "eval_prompt_1 = df_syn['Questions'].tolist()\n",
        "\n",
        "\n",
        "test_lst = []\n",
        "for i in eval_prompt_1:\n",
        "    item = \"Answer with the option's letter from the given choices directly and don't provide extra choices or explanations.\" + '\\n' + i + '\\n' + \"Answer is:\"\n",
        "\n",
        "    inputs = tokenizer(item, return_tensors=\"pt\").to('cuda')\n",
        "    generate_ids = model.generate(**inputs, max_new_tokens=100)\n",
        "    test = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    test_lst.append(test)\n",
        "\n",
        "df_llama_2_7b = pd.DataFrame({'col1': test_lst})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy_VX_qGt4JJ"
      },
      "source": [
        "## LLaMA-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdqMmjEktyjz"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_id = \"meta-llama/Meta-Llama-3-8B-instruct\"\n",
        "\n",
        "\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    model_kwargs={\n",
        "        \"torch_dtype\": torch.float16,\n",
        "        \"quantization_config\": {\"load_in_4bit\": True},\n",
        "        \"low_cpu_mem_usage\": True,\n",
        "    },\n",
        ")\n",
        "\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Answer following question by choosing an option! Please ONLY provide letter choice as answer to question. \"},\n",
        "    {\"role\": \"user\", \"content\": \"put the question here\"},\n",
        "]\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"<csv_file>\")\n",
        "\n",
        "column_mapping = {'Questions': 'content'}\n",
        "\n",
        "\n",
        "\n",
        "index_to_update = 1\n",
        "\n",
        "update_message = []\n",
        "\n",
        "for i in range(len(df)):\n",
        "    for df_col, dict_key in column_mapping.items():\n",
        "            messages[index_to_update][dict_key] = df[df_col].values[i]\n",
        "\n",
        "            prompt = pipeline.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True\n",
        "            )\n",
        "\n",
        "            terminators = [\n",
        "            pipeline.tokenizer.eos_token_id,\n",
        "            pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "            ]\n",
        "\n",
        "            outputs = pipeline(\n",
        "            prompt,\n",
        "            max_new_tokens=256,\n",
        "            eos_token_id=terminators,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9\n",
        "\n",
        "            )\n",
        "\n",
        "\n",
        "            temp_dict = {\n",
        "                \"question\": df[df_col].values[i],\n",
        "                \"generated_answer\": outputs[0][\"generated_text\"][len(prompt):]\n",
        "            }\n",
        "            update_message.append(temp_dict)\n",
        "\n",
        "\n",
        "second_part = model_id.split('/')[1]\n",
        "file_name = second_part + \"_affordance.csv\"\n",
        "\n",
        "\n",
        "directory_name = f\"pathtodirctory{second_part}\"\n",
        "\n",
        "\n",
        "if not os.path.exists(directory_name):\n",
        "    os.makedirs(directory_name)\n",
        "    print(\"Directory created:\", directory_name)\n",
        "else:\n",
        "    print(\"Directory already exists:\", directory_name)\n",
        "\n",
        "\n",
        "full_path = f\"{directory_name}/{file_name}\"\n",
        "\n",
        "dataframe_tmp = pd.DataFrame.from_dict(update_message, orient='columns')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqoMav_mx1R"
      },
      "source": [
        "### flan-alpaca-gpt4-xl cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vAAM0hQmx1S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def formating(dataframe):\n",
        "    listofwords = []\n",
        "\n",
        "    df_conversion = dataframe.copy()\n",
        "\n",
        "\n",
        "    for word in df_conversion[\"col1\"].values.tolist():\n",
        "\n",
        "        before_keyword, keyword, after_keyword = word[0]['generated_text'].partition(')')\n",
        "        listofwords.append(before_keyword.lower())\n",
        "\n",
        "    df_syn.loc[:,'Generated_Answers'] = listofwords\n",
        "    print(np.unique(df_syn.iloc[:,2]), np.unique(df_syn.iloc[:,1]))\n",
        "\n",
        "    return df_syn\n",
        "\n",
        "final_df = formating(df_llama_2_7b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AytDlKQ8mx1S"
      },
      "source": [
        "### LLaMA-2 cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJa9TlHlmx1S",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def formating(dataframe):\n",
        "    listofwords = []\n",
        "\n",
        "    df_conversion = dataframe.copy()\n",
        "\n",
        "    for word in df_conversion['col1'].values.tolist():\n",
        "\n",
        "        keyword = 'Answer is:'\n",
        "        before_keyword, keyword, after_keyword = word.partition(keyword)\n",
        "        listofwords.append(after_keyword)\n",
        "\n",
        "\n",
        "\n",
        "    listofwords_ = []\n",
        "    for words_ in listofwords:\n",
        "        keyword = ')'\n",
        "        before_keyword, keyword, after_keyword = words_.partition(keyword)\n",
        "        listofwords_.append(before_keyword)\n",
        "\n",
        "    df_syn.loc[:,'Generated_Answers'] = listofwords_\n",
        "    print(np.unique(df_syn.iloc[:,2]), np.unique(df_syn.iloc[:,1]))\n",
        "\n",
        "    return df_syn\n",
        "\n",
        "\n",
        "\n",
        "final_df = formating(dataframe_tmp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS0knRJJmx1T"
      },
      "source": [
        "### LLaMA-3 cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aOteBlWmx1U",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model_name = \"meta-llama/Meta-Llama-3-8B-instruct\"\n",
        "\n",
        "def formating(dataframe):\n",
        "    listofwords = []\n",
        "\n",
        "    df_conversion = dataframe.copy()\n",
        "\n",
        "    listofwords_ = []\n",
        "    for words_ in df_conversion[\"generated_answer\"].values.tolist():\n",
        "        keyword = ')'\n",
        "        before_keyword, keyword, after_keyword = words_.partition(keyword)\n",
        "        listofwords_.append(before_keyword)\n",
        "\n",
        "\n",
        "    df_syn.loc[:,'Generated_Answers'] = listofwords_\n",
        "    print(np.unique(df_syn.iloc[:,2]), np.unique(df_syn.iloc[:,1]))\n",
        "\n",
        "    return df_syn\n",
        "\n",
        "final_df = formating(dataframe_tmp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XceJtz1Lmx1U"
      },
      "source": [
        "## Flan-T5 cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hvH4Y7Xmx1U",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def formating(dataframe):\n",
        "    listofwords = []\n",
        "\n",
        "    df_conversion = dataframe.copy()\n",
        "\n",
        "    for word in df_conversion['Generated_Answers'].values.tolist():\n",
        "\n",
        "        keyword = ')'\n",
        "        before_keyword, keyword, after_keyword = word.partition(keyword)\n",
        "        listofwords.append(before_keyword)\n",
        "\n",
        "    df_syn.loc[:,'Generated_Answers'] = listofwords\n",
        "    return df_syn\n",
        "\n",
        "final_df = formating(df_tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKEb0tMCsU3v"
      },
      "outputs": [],
      "source": [
        "def formatting_text_only(df):\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace('\\n','', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace('\\n\\n','', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' a','a', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace([' \\(b'],'b', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace([' c', 'c ', ' \\(c'],'c', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' d','d', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' \\(d','d', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' \\(a','a', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace([' b',' b'],'b', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' e','e', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' f','f', regex=True)\n",
        "    df.iloc[:,2] = df.iloc[:,2].replace(' A','a', regex=True)\n",
        "    print(np.unique(df.iloc[:,2]), np.unique(df.iloc[:,1]))\n",
        "    return df\n",
        "\n",
        "df_final = formatting_text_only(final_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YghwRdqzqPx7"
      },
      "source": [
        "## Unifiedqa2 (large-1363200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIhVvmlGqVC6"
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = \"allenai/unifiedqa-v2-t5-large-1363200\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "def run_model(input_string, **generator_args):\n",
        "    input_string = \"Answer with the option's letter from the given choices directly.\\n\" + input_string\n",
        "    input_ids = tokenizer.encode(input_string, return_tensors=\"pt\")\n",
        "    res = model.generate(input_ids, **generator_args)\n",
        "    return tokenizer.batch_decode(res, skip_special_tokens=True)\n",
        "\n",
        "df_list = []\n",
        "for item in df_syn['Questions'].tolist():\n",
        "    df_list.append(run_model(item))\n",
        "df_append = pd.DataFrame(df_list, columns=['Generated_Answers'])\n",
        "concat = pd.concat([df_syn, df_append], axis=1)\n",
        "concat.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sS77OfuSrRYZ"
      },
      "outputs": [],
      "source": [
        "def extract_question_and_options(question_text):\n",
        "    question_options = question_text.split('\\n')\n",
        "    question = question_options[0].strip()\n",
        "    options = [option.strip() for option in question_options[1:] if option.strip()]\n",
        "    return question, options\n",
        "\n",
        "def read_csv():\n",
        "\n",
        "    df = df_syn\n",
        "\n",
        "    questions = []\n",
        "    option_lists = []\n",
        "    for index, row in df.iterrows():\n",
        "        question_text = str(row[0])\n",
        "\n",
        "        question, options = extract_question_and_options(question_text)\n",
        "        questions.append(question)\n",
        "        option_lists.append(options)\n",
        "\n",
        "    return questions, option_lists\n",
        "\n",
        "\n",
        "\n",
        "questions, options = read_csv()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDcU8XqErW0G"
      },
      "outputs": [],
      "source": [
        "combined_list = []\n",
        "\n",
        "options_lower = [[x.lower() for x in inner_list] for inner_list in options]\n",
        "\n",
        "combined_list = []\n",
        "\n",
        "for i, row in concat[\"Generated_Answers\"].items():\n",
        "    row_lower = row.lower()\n",
        "    matched = False\n",
        "    for j, item in enumerate(options[i]):\n",
        "        if row_lower in item.lower():\n",
        "            combined_list.append((i, item, \"Matched\"))\n",
        "            matched = True\n",
        "            break\n",
        "    if not matched:\n",
        "        combined_list.append((i, row, \"Unmatched\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyQmRLBJre7W"
      },
      "outputs": [],
      "source": [
        "df_match_unmatch = pd.DataFrame(combined_list, columns=['Index', 'Item', 'Status'])\n",
        "concat_final = pd.concat([df_match_unmatch, df_syn], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvHiTD7srimM"
      },
      "outputs": [],
      "source": [
        "def formating_unifiedqa(dataframe):\n",
        "    listofwords = []\n",
        "\n",
        "    df_conversion = dataframe.copy()\n",
        "\n",
        "    listofwords_ = []\n",
        "    for words_ in df_conversion[\"Item\"].tolist():\n",
        "        keyword = ')'\n",
        "        before_keyword, keyword, after_keyword = words_.partition(keyword)\n",
        "        listofwords_.append(before_keyword)\n",
        "\n",
        "    concat_final.loc[:,'Generated_Answers_final'] = listofwords_\n",
        "    return concat_final\n",
        "\n",
        "\n",
        "final_df = formating_unifiedqa(concat_final)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTv-O5HTmx1V"
      },
      "source": [
        "## Save the output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6waUm71Rmx1W",
        "tags": []
      },
      "outputs": [],
      "source": [
        "second_part = model_name.split('/')[1]\n",
        "file_name = second_part + \"_\" + f\"habitat.csv\"\n",
        "\n",
        "path = directory_name +  \"/\" + f\"{second_part}\"\n",
        "\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "    print(\"Directory created:\", path)\n",
        "else:\n",
        "    print(\"Directory already exists:\", path)\n",
        "\n",
        "\n",
        "full_path = f\"{path}/{file_name}\"\n",
        "\n",
        "df_final.to_csv(full_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSE2x3Kxmx1X"
      },
      "source": [
        "# Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK8QlG4Mmx1X",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def accuracy(df):\n",
        "    generated = df.iloc[:,2]\n",
        "    groundtruth = df.iloc[:,1]\n",
        "\n",
        "    return accuracy_score(groundtruth, generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoV_9fXOmx1h",
        "tags": []
      },
      "outputs": [],
      "source": [
        "blue_bar = (.52, 0.44, 0.53, .44, .54, .52, .56, .41, .55, .53, .57)\n",
        "\n",
        "\n",
        "llms = ['Llama-2-7b', 'Llama-2-13b', 'Llama-2-70b', 'Llama-3-8b','Llama-3-70b',\n",
        "        'Flan-base', 'Flan-small', 'Flan-large', 'Flan-xl', 'Flan_alpaca_gpt4-xl',\n",
        "       'Unifiedqa-v2']\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "\n",
        "\n",
        "plt.bar(llms, blue_bar, color ='blue', width = 0.3)\n",
        "\n",
        "plt.xlabel(\"Model\", fontdict={'fontsize': 20})\n",
        "plt.ylabel(\"Accuracy\", fontdict={'fontsize': 20})\n",
        "plt.title(\"Habitat-centering\", fontdict={'fontsize': 20})\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig('pathtosave', dpi=300)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dDjz3enmx1k",
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXuDGnn2mx1l",
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaB90wXQmx1m",
        "tags": []
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-0Qg83jmx1o"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
